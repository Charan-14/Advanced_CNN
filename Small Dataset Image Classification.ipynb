{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Xihelm Image Classification.ipynb","provenance":[],"mount_file_id":"18-4CDfmyUYi3r0UFojc2tSTkda44BDRc","authorship_tag":"ABX9TyPKpzQzgw9eHOLjn2QpGh4Y"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"UYO3vjePkDKG"},"source":["#import Libraries\n","import zipfile\n","from google.colab import drive\n","import os\n","import os.path\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import keras\n","from tensorflow.keras.applications import *\n","from tensorflow.keras import models, layers, optimizers\n","import tensorflow as tf\n","from keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.applications.inception_v3 import InceptionV3"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-tVwnDwaKbwf"},"source":["**Summary**\n","\n","For training the on this small dataset of 100 images in each class, It was obvious that we had to leverage the power of transfer learning\n","\n","Using pretrained Weights derived by training models on imagenet dataset\n","\n","I initially decided to use the EfficientNetB0 Network as it had significantly lesser parameters and the highest accuracy compared to other dense networks.But the loss was oscilating similar with Resnet50.\n","\n","Then i decided to use InceptionV3 with RMSprop and the training loss was going down progressively and good accuracy was obtained.\n","\n","Dropout and Data Augmentation was done to prevent overfitting\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OK9784KBIE9W","executionInfo":{"status":"ok","timestamp":1622846137376,"user_tz":-330,"elapsed":4,"user":{"displayName":"Charanpreet Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP6joEBt7gXMO2ajOweJJZWdRe-HQ-rCSYb5_wzw=s64","userId":"12494653573109071690"}},"outputId":"47c16e50-5b69-46d9-9dfe-2c7a80b837df"},"source":["zip_loc = \"/content/drive/My Drive/Xihelm Dataset/dataset cv ai 2021.zip\"\n","DATADIR = \"/content/drive/My Drive/Xihelm Dataset/\"\n","drive_loc = \"/content/drive/\"\n","CATEGORIES = []\n","IMG_SIZE = 150\n","class ImageClassification():\n","\n","    def __init__(self):\n","        drive.mount(drive_loc)\n","\n","    def unzip(self, zip_loc, unzip_loc):\n","        zip = zipfile.ZipFile(zip_loc, 'r')\n","        zip.extractall(unzip_loc)\n","        print(\"File Extracted\")\n","    \n","    def labelExtract(self):\n","        path = DATADIR\n","        for folder in os.listdir(DATADIR):\n","            if os.path.isdir(path+folder):\n","                CATEGORIES.append(folder) \n","        return len(CATEGORIES)\n","    \n","    def visualizeInit(self, numImage):\n","        for category in CATEGORIES:\n","            path = os.path.join(DATADIR,category)\n","            for img in os.listdir(path)[:numImage]:\n","                img_arr = cv2.imread(os.path.join(path,img))\n","                img_arr = cv2.cvtColor(img_arr, cv2.COLOR_BGR2RGB)\n","                plt.imshow(img_arr)\n","                plt.show()\n","\n","    def data_generation(self):\n","        image_generator = ImageDataGenerator(rescale=1/255.0, \n","                                             validation_split=0.15,\n","                                             rotation_range = 40,\n","                                             zoom_range = 0.2,\n","                                             shear_range = 0.2,\n","                                             width_shift_range=0.2,\n","                                             height_shift_range=0.2,\n","                                             horizontal_flip=True,\n","                                             fill_mode=\"nearest\")    \n","\n","        train_dataset = image_generator.flow_from_directory(batch_size=1,\n","                                                 directory=DATADIR,\n","                                                 shuffle=True,\n","                                                 target_size=(IMG_SIZE, IMG_SIZE), \n","                                                 subset=\"training\",\n","                                                 class_mode='categorical')\n","\n","        validation_dataset = image_generator.flow_from_directory(batch_size=1,\n","                                                 directory=DATADIR,\n","                                                 shuffle=True,\n","                                                 target_size=(IMG_SIZE, IMG_SIZE), \n","                                                 subset=\"validation\",\n","                                                 class_mode='categorical')\n","        return train_dataset, validation_dataset\n","\n","    def saveFeatures(self,featureName, labelName, features, labels):\n","        \n","        np.save(drive_loc+DATADIR+featureName, features)\n","        np.save(drive_loc+DATADIR+labelName, labels)\n","    \n","    def loadFeatures(self, featureName, labelName):\n","        \n","        features = np.load(drive_loc+DATADIR+featureName)\n","        labels = np.load(drive_loc+DATADIR+labelName)\n","\n","        return features, labels\n","\n","    def create_model(self,NUM_CLASSES):\n","        base = InceptionV3(include_top=False, weights=\"imagenet\", input_shape=(IMG_SIZE,IMG_SIZE,3))\n","        for layer in base.layers:\n","            layer.trainable = False\n","        model = models.Sequential()\n","        model.add(base)\n","        model.add(layers.Flatten())\n","        model.add(layers.Dense(1024, activation='relu'))\n","        dropout_rate = 0.2\n","        model.add(layers.Dropout(dropout_rate, name=\"dropout_out\"))\n","\n","        model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\", name=\"fc_out\"))\n","        model.summary()\n","        return model\n","\n","    def fitModel(self, model,train,valid, epochs):\n","        optimizer = tf.keras.optimizers.RMSprop(learning_rate=1e-3)\n","        model.compile(loss = \"categorical_crossentropy\",\n","                      optimizer=optimizer,\n","                      metrics=[\"accuracy\"])\n","        history = model.fit_generator(train, epochs=epochs, validation_data=valid)\n","        return history\n","    \n","    def dataPrep(self, filepath):\n","        img = cv2.imread(filepath)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","        img_array = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n","        img_array.reshape(-1,IMG_SIZE,IMG_SIZE,3)\n","        \n","        return img_array\n","ic = ImageClassification()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xscAtogUPCMg","executionInfo":{"status":"ok","timestamp":1622846139798,"user_tz":-330,"elapsed":7,"user":{"displayName":"Charanpreet Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP6joEBt7gXMO2ajOweJJZWdRe-HQ-rCSYb5_wzw=s64","userId":"12494653573109071690"}},"outputId":"d70d6d1f-7a5e-4366-8721-ac141cc7e830"},"source":["# ic.unzip(zip_loc,DATADIR)\n","NUM_CLASSES = ic.labelExtract()\n","print(CATEGORIES, NUM_CLASSES)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["['animals', 'buildings', 'landscapes'] 3\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DBrNTagdhfuU"},"source":["ic.visualizeInit(5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TNBKe2t6pxTK","executionInfo":{"status":"ok","timestamp":1622846141614,"user_tz":-330,"elapsed":5,"user":{"displayName":"Charanpreet Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP6joEBt7gXMO2ajOweJJZWdRe-HQ-rCSYb5_wzw=s64","userId":"12494653573109071690"}},"outputId":"6e58c339-cef3-4780-8d66-3337247abba1"},"source":["train_dataset, validation_dataset = ic.data_generation()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Found 255 images belonging to 3 classes.\n","Found 45 images belonging to 3 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Grh8bsFSIleM","executionInfo":{"status":"ok","timestamp":1622846145344,"user_tz":-330,"elapsed":2451,"user":{"displayName":"Charanpreet Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP6joEBt7gXMO2ajOweJJZWdRe-HQ-rCSYb5_wzw=s64","userId":"12494653573109071690"}},"outputId":"c772158b-ef73-4b91-c54f-dea5624a6d34"},"source":["model = ic.create_model(NUM_CLASSES)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","inception_v3 (Functional)    (None, 3, 3, 2048)        21802784  \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 18432)             0         \n","_________________________________________________________________\n","dense_1 (Dense)              (None, 1024)              18875392  \n","_________________________________________________________________\n","dropout_out (Dropout)        (None, 1024)              0         \n","_________________________________________________________________\n","fc_out (Dense)               (None, 3)                 3075      \n","=================================================================\n","Total params: 40,681,251\n","Trainable params: 18,878,467\n","Non-trainable params: 21,802,784\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gXRVyPjEJB-K","executionInfo":{"status":"ok","timestamp":1622846555384,"user_tz":-330,"elapsed":410047,"user":{"displayName":"Charanpreet Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP6joEBt7gXMO2ajOweJJZWdRe-HQ-rCSYb5_wzw=s64","userId":"12494653573109071690"}},"outputId":"a59f031a-9c9a-4799-bf63-5033d8dec61f"},"source":["history = ic.fitModel(model, train_dataset, validation_dataset, 60)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/60\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py:1940: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n","  warnings.warn('`Model.fit_generator` is deprecated and '\n"],"name":"stderr"},{"output_type":"stream","text":["255/255 [==============================] - 11s 31ms/step - loss: 25.6606 - accuracy: 0.5765 - val_loss: 26.1423 - val_accuracy: 0.4889\n","Epoch 2/60\n","255/255 [==============================] - 7s 26ms/step - loss: 10.9223 - accuracy: 0.6431 - val_loss: 3.0801 - val_accuracy: 0.8444\n","Epoch 3/60\n","255/255 [==============================] - 7s 26ms/step - loss: 8.8894 - accuracy: 0.6902 - val_loss: 27.9907 - val_accuracy: 0.4222\n","Epoch 4/60\n","255/255 [==============================] - 7s 26ms/step - loss: 7.3565 - accuracy: 0.7137 - val_loss: 1.9182 - val_accuracy: 0.8222\n","Epoch 5/60\n","255/255 [==============================] - 7s 26ms/step - loss: 4.1605 - accuracy: 0.7765 - val_loss: 2.6539 - val_accuracy: 0.8222\n","Epoch 6/60\n","255/255 [==============================] - 7s 26ms/step - loss: 4.9540 - accuracy: 0.7216 - val_loss: 2.8754 - val_accuracy: 0.7556\n","Epoch 7/60\n","255/255 [==============================] - 7s 26ms/step - loss: 3.0105 - accuracy: 0.8039 - val_loss: 2.4406 - val_accuracy: 0.7556\n","Epoch 8/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.9491 - accuracy: 0.8000 - val_loss: 3.4400 - val_accuracy: 0.7111\n","Epoch 9/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.0081 - accuracy: 0.8235 - val_loss: 3.3326 - val_accuracy: 0.7778\n","Epoch 10/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.2047 - accuracy: 0.8627 - val_loss: 1.8036 - val_accuracy: 0.7778\n","Epoch 11/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.2531 - accuracy: 0.8510 - val_loss: 15.1552 - val_accuracy: 0.4889\n","Epoch 12/60\n","255/255 [==============================] - 7s 26ms/step - loss: 3.0579 - accuracy: 0.8196 - val_loss: 3.8715 - val_accuracy: 0.7111\n","Epoch 13/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.4241 - accuracy: 0.7765 - val_loss: 3.9964 - val_accuracy: 0.6667\n","Epoch 14/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.3310 - accuracy: 0.8353 - val_loss: 1.2558 - val_accuracy: 0.8222\n","Epoch 15/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.6098 - accuracy: 0.8706 - val_loss: 2.9502 - val_accuracy: 0.7556\n","Epoch 16/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.2275 - accuracy: 0.8549 - val_loss: 1.3575 - val_accuracy: 0.8667\n","Epoch 17/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.2788 - accuracy: 0.8196 - val_loss: 1.7810 - val_accuracy: 0.8444\n","Epoch 18/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.7984 - accuracy: 0.8431 - val_loss: 3.7562 - val_accuracy: 0.6667\n","Epoch 19/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.4656 - accuracy: 0.8941 - val_loss: 5.1570 - val_accuracy: 0.7111\n","Epoch 20/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.9667 - accuracy: 0.8431 - val_loss: 2.6652 - val_accuracy: 0.7556\n","Epoch 21/60\n","255/255 [==============================] - 7s 26ms/step - loss: 3.6599 - accuracy: 0.8431 - val_loss: 2.4729 - val_accuracy: 0.8667\n","Epoch 22/60\n","255/255 [==============================] - 7s 26ms/step - loss: 3.7398 - accuracy: 0.8039 - val_loss: 3.3601 - val_accuracy: 0.8667\n","Epoch 23/60\n","255/255 [==============================] - 7s 26ms/step - loss: 3.2200 - accuracy: 0.8627 - val_loss: 3.2146 - val_accuracy: 0.8222\n","Epoch 24/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.6746 - accuracy: 0.8784 - val_loss: 1.4558 - val_accuracy: 0.7778\n","Epoch 25/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.3342 - accuracy: 0.8275 - val_loss: 4.3846 - val_accuracy: 0.7778\n","Epoch 26/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.9832 - accuracy: 0.8314 - val_loss: 3.7236 - val_accuracy: 0.7778\n","Epoch 27/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.6794 - accuracy: 0.8510 - val_loss: 2.9248 - val_accuracy: 0.7778\n","Epoch 28/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.4302 - accuracy: 0.8392 - val_loss: 4.9141 - val_accuracy: 0.7556\n","Epoch 29/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.8698 - accuracy: 0.8706 - val_loss: 2.8986 - val_accuracy: 0.7556\n","Epoch 30/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.0524 - accuracy: 0.9020 - val_loss: 2.7754 - val_accuracy: 0.8222\n","Epoch 31/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.4921 - accuracy: 0.8588 - val_loss: 1.1538 - val_accuracy: 0.8889\n","Epoch 32/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.0414 - accuracy: 0.9098 - val_loss: 2.0817 - val_accuracy: 0.7778\n","Epoch 33/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.4265 - accuracy: 0.8863 - val_loss: 9.6480 - val_accuracy: 0.6000\n","Epoch 34/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.0643 - accuracy: 0.8510 - val_loss: 3.3987 - val_accuracy: 0.8000\n","Epoch 35/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.6799 - accuracy: 0.8431 - val_loss: 3.9264 - val_accuracy: 0.7556\n","Epoch 36/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.1560 - accuracy: 0.8627 - val_loss: 2.7558 - val_accuracy: 0.8000\n","Epoch 37/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.0829 - accuracy: 0.8980 - val_loss: 2.1628 - val_accuracy: 0.7778\n","Epoch 38/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.0717 - accuracy: 0.8863 - val_loss: 2.4393 - val_accuracy: 0.8222\n","Epoch 39/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.5235 - accuracy: 0.8863 - val_loss: 4.0283 - val_accuracy: 0.6667\n","Epoch 40/60\n","255/255 [==============================] - 7s 27ms/step - loss: 1.2969 - accuracy: 0.8863 - val_loss: 2.8423 - val_accuracy: 0.7778\n","Epoch 41/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.0244 - accuracy: 0.9020 - val_loss: 1.6922 - val_accuracy: 0.8222\n","Epoch 42/60\n","255/255 [==============================] - 7s 26ms/step - loss: 0.9857 - accuracy: 0.8980 - val_loss: 3.2108 - val_accuracy: 0.7556\n","Epoch 43/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.3152 - accuracy: 0.9098 - val_loss: 2.8667 - val_accuracy: 0.8889\n","Epoch 44/60\n","255/255 [==============================] - 7s 26ms/step - loss: 0.9704 - accuracy: 0.9137 - val_loss: 3.1883 - val_accuracy: 0.7556\n","Epoch 45/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.3179 - accuracy: 0.8980 - val_loss: 3.2975 - val_accuracy: 0.8444\n","Epoch 46/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.9207 - accuracy: 0.8902 - val_loss: 8.3070 - val_accuracy: 0.6667\n","Epoch 47/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.6782 - accuracy: 0.8902 - val_loss: 3.2819 - val_accuracy: 0.7556\n","Epoch 48/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.4090 - accuracy: 0.9255 - val_loss: 4.4874 - val_accuracy: 0.7778\n","Epoch 49/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.4946 - accuracy: 0.8941 - val_loss: 3.9344 - val_accuracy: 0.8222\n","Epoch 50/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.1283 - accuracy: 0.8863 - val_loss: 3.9762 - val_accuracy: 0.7556\n","Epoch 51/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.7050 - accuracy: 0.9020 - val_loss: 4.7731 - val_accuracy: 0.7556\n","Epoch 52/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.9053 - accuracy: 0.8902 - val_loss: 2.8200 - val_accuracy: 0.8444\n","Epoch 53/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.3032 - accuracy: 0.9216 - val_loss: 2.4530 - val_accuracy: 0.8444\n","Epoch 54/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.8455 - accuracy: 0.9137 - val_loss: 4.0216 - val_accuracy: 0.7333\n","Epoch 55/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.1704 - accuracy: 0.9176 - val_loss: 4.5003 - val_accuracy: 0.7111\n","Epoch 56/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.4636 - accuracy: 0.8980 - val_loss: 2.5020 - val_accuracy: 0.8000\n","Epoch 57/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.4757 - accuracy: 0.9176 - val_loss: 3.9400 - val_accuracy: 0.8667\n","Epoch 58/60\n","255/255 [==============================] - 7s 26ms/step - loss: 2.0442 - accuracy: 0.9098 - val_loss: 10.1138 - val_accuracy: 0.7556\n","Epoch 59/60\n","255/255 [==============================] - 7s 26ms/step - loss: 1.5953 - accuracy: 0.9098 - val_loss: 3.0157 - val_accuracy: 0.8667\n","Epoch 60/60\n","255/255 [==============================] - 7s 27ms/step - loss: 0.8705 - accuracy: 0.9294 - val_loss: 2.4841 - val_accuracy: 0.8444\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mDYH5UYxy6Tf"},"source":["Model Training Accuracy - 92.04%, Model Validaiton Set Accuracy - 84.4%"]},{"cell_type":"code","metadata":{"id":"ZmunjBS76mIl","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1622846846008,"user_tz":-330,"elapsed":38536,"user":{"displayName":"Charanpreet Singh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjP6joEBt7gXMO2ajOweJJZWdRe-HQ-rCSYb5_wzw=s64","userId":"12494653573109071690"}},"outputId":"1056db40-b7fe-4bff-99f8-c9a22182759f"},"source":["model.save(DATADIR+\"incepv3.model\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["INFO:tensorflow:Assets written to: /content/drive/My Drive/Xihelm Dataset/incepv3.model/assets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"KARR4uQjNRu5"},"source":[""],"execution_count":null,"outputs":[]}]}